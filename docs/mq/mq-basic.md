> 本文从应用场景、常见问题、解决方案、技术方案选型等角度聊一聊消息队列中间件

在设计高并发系统时，消息队列中间件是重要的组成部分。它就像一个防御工事，当流量洪流瞬间袭来时，可以将其进行分散，瓦解，保证系统正常稳定运行。
如果说缓存系统解决的是高并发系统下的查询性能瓶颈，那么消息队列系统解决的就是高并发系统下的写入性能瓶颈。

#### 应用场景
- 流量削峰：秒杀系统
  - 秒杀活动开始的瞬间，用户点击下单，大量写请求涌入
  - 请求操作会先被存储到消息队列，然后并发地，按顺序地让不同业务系统进行消费
- 异步处理：非核心流程异步处理，提升效率
  - 比如用户下单后增加积分、发通知，通知仓储服务发货等服务
  - 与核心下单服务分开，让下单服务处理消息更快，进而提升效率
- 系统解耦：不同的服务专注于不同的任务，统计订单金额服务等
  - 各个服务通过订阅消息队列中自己关心的Topic，拿到消息，自己处理自己的事就好了
  - 增加系统鲁棒性

#### 常见问题
**如何保证消息仅仅被消费一次**
> 我们根据消息传递的链路来分析一下

- 消息从生产者写入到消息队列
  - 问题：可能存在网络抖动
  - 方案：采用消息重传，重试2-3次
  - 后果：可能会造成消息重复
- 消息在消息队列中的存储
  - 问题：消息在 Kafka 中是存储在本地磁盘上的，为了较少消息存储时对磁盘的随机I/O，我们一般会将消息先写入到操作系统的 Page Cache 中，然后再找合适的时机刷新到磁盘上。有可能数据还没落盘就故障了，此时消息丢失
  - 方案：以集群方式部署 Kafka 服务，通过部署多个副本备份数据保证消息尽量不丢失
    - Leader 负责消息的写入和消费，多个 Follower 负责数据备份
    - Follower 中有一个特殊的集合叫做 ISR（in-sync replicas）
    - 由于默认消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，还没来得及复制到 Follower 的消息还是会丢失。
    - 为了解决这个问题，Kafka 为生产者提供了一个选项叫做 acks，当此选项被设置为 all 时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR 的确认后才被认为发送成功
- 消息被消费者消费过程
  - 问题：如何保证消息只被消费一次
  - 方案：只要保证即使消费到了重复的消息，消费过程是“幂等”的
    - Kafka 目前已支持生产过程幂等性，这种特性保证消息虽然可能在生产端产生重复，但是最终在消息队列存储时只会存储一份
    - 它的做法是给每一个生产者一个唯一ID，为生产的每一条消息也赋予一个唯一ID，消息队列服务端会存储 "生产者ID-最后一条消息ID" 的映射。当该生产者产生一条新的消息时，消息队列服务端会对比消息ID是否与存储的最后一条ID一致，如果一致就认为是重复消息，服务端会自动丢弃
    - 在消费端，通用层面上看，我们也可以生成一个全局唯一的消息ID，消息被处理之后将ID存入数据库，处理之前查询此ID是否被消费过，如果被消费过就放弃消费
    - 极端情况下，消息处理之后，还没写入数据库，消费者宕机重启后发现数据库没数据，还是会重复执行两次消费逻辑，这时你就需要引入事务机制，保证消息处理和写入数据库必须同时成功或者同时失败，这样成本就更高了
    - 在业务层面上看，我们可以通过乐观锁来避免重复消费。在数据表中增加一个版本号的字段，在生产消息时先查询这个账户的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新操作时带上版本号，如果版本号不对了，就不用消费了
    - 类似的思想还有根据业务数据状态来判断，比如订单支付后变更状态为已支付，如果订单当前状态已经为已支付则忽略此消息

**如何监控消息延迟**
- 方式一：使用消息队列提供的工具，通过监控消息的堆积来完成
  - 在 Kafka0.9 版本之后，消费进度被放到了一个专门的 Topic “_consumer_offsets“ 里面，之前的版本是存储在 ZooKeeper 中
  - Kafka 提供了工具叫做 "kafka-consumer-groups.sh" 在安装包的 bin 目录下
  - Kafka 还通过 JMX 工具暴露了消息堆积的数据，可以通过写代码来获取，并方便地输出到监控系统中
- 方式二：通过生成监控消息的方式来监控消息的延迟情况
  - 先定义一种特殊的消息，然后启动一个监控程序将这个消息定时地循环写入到消息队列中，消息的内容可以是生成消息的时间戳
  - 该程序也会作为队列的消费者消费数据。消费到这个消息时可以和这个消息的生成时间做比较，如果时间差达到某个阀值就可以报警了

**如何减少消息延迟**
- 消费端：提升消费者的消息处理能力
  - 在 Kafka 中，可以通过增加分区来提高消费者的处理能力
    - 因为在 Kafka 中，一个 Topic 可以配置多个 Partition，数据会被平均或者按照生产者指定的方式写入到多个分区中，在消费时，Kafka 约定一个分区只能被一个消费者消费（多个消费者消费一个分区的数据就需要加锁了影响性能）
    - 所以，话题的分区数量决定了消费的并行度，增加多余的消费者是没用的
  - 增加单个消费者的并行处理消息能力，使用多线程来执行消费逻辑
- 消息队列：提升消息队列的读取性能
  - 使用本地磁盘存储方式而不是数据库存储方式，因为数据库存在性能瓶颈，QPS 只能到 2000
  - 减少数据拷贝次数。把磁盘中的数据通过网络发送出去会有四次数据拷贝
    - 数据从磁盘拷贝到内核缓冲区
    - 系统调用将内核缓冲区的数据拷贝到用户缓冲区
    - 用户缓冲区的数据被写入到 socket缓冲区
    - 操作系统再将 socket缓冲区的数据拷贝到网卡的缓冲区中
    - 操作系统提供了 Sendfile 函数可以减少数据被拷贝的次数，使用 Sendfile，内核缓冲区数据会直接拷贝到socket缓冲区，节省了一次拷贝的过程

#### 技术方案选型
**RabbitMQ**
- 可靠性高
- 采用 Erlang 语言实现的 AMQP 协议的消息中间件，用于在分布式系统中存储转发消息。
- 消息传递模式为典型的点对点模式，但也可以通过设置交换器类型来实现发布订阅模式
- 消息堆积方式为典型的内存式堆积，但在某些条件触发后会有换页动作来将内存中的消息换页到磁盘
- 能够支持 MQTT 消息协议，所以其在物联应用中获得一席之地
- 就目前而言，在金融支付领域使用 RabbitMQ 居多，而在日志处理、大数据等方面 Kafka 使用居多，随着 RabbitMQ 性能的不断提升和 Kafka 可靠性的进一步增强，相信彼此都能在以前不擅长的领域分得一杯羹。

**Kafka**
- 轻量级，高效，可靠性相对低一点
- 由 LinkedIn 公司采用 Scala 语言开发的一个分布式、多分区、多副本且基于 zookeeper 协调的分布式消息系统，它是一种高吞吐量的分布式发布订阅消息系统，以可水平扩展和高吞吐率而被广泛使用
- 是一种典型的发布/订阅（Pub/Sub）模式，当然也能以点对点的形式消费，你完全可以把其消费组（consumer group）的概念看成是队列的概念
- 消息堆积方式为典型的磁盘式堆积，所有的消息都存储在磁盘上，从另外一个角度讲，消息堆积也为消息中间件提供了冗余存储的功能。援引 纽约时报的案例，其直接将 Kafka 用作存储系统
- Kafka 自 0.11 版本开始引入了幂等性和事务，Kafka 的幂等性是指单个生产者对于单分区单会话的幂等，而事务可以保证原子性地写入到多个分区，即写入到多个分区的消息要么全部成功，要么全部回滚，这两个功能加起来可以让 Kafka 具备 EOS（Exactly Once Semantic）的能力。
- 一般 RabbitMQ 的单机 QPS 在万级别之内，而 Kafka 的单机 QPS 可以维持在十万级别，甚至可以达到百万级。

**RocketMQ**
- 阿里开源的消息中间件，由 Java 语言开发，具备高吞吐量、高可用性、适合大规模分布式系统应用
- 起源于 Kafka，对消息的可靠传输及事务性做了优化

#### 参考资料
- [https://www.infoq.cn/article/kafka-vs-rabbitmq](https://www.infoq.cn/article/kafka-vs-rabbitmq)
- 《高并发系统设计40问》